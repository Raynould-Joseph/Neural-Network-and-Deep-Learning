{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlhCnvkCKTpvVAwA+vn/Yo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raynould-Joseph/Neural-Network-and-Deep-Learning/blob/main/Lab4_ADALINE_and_MELADINE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of ADALINE Network"
      ],
      "metadata": {
        "id": "85KEDdg85_3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5po_xr_5drs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adalin for OR"
      ],
      "metadata": {
        "id": "6HOpNSl69fHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANbKAABI3r8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d50c3f1-3214-408b-c56d-ec3687ca691e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]] [ 1  1  1 -1]\n",
            "epoch : 1\n",
            "--------\n",
            "\n",
            "case:1\n",
            "---------\n",
            "Yn= 0.1+(0.1*1)+(0.1*1)\n",
            "=0.30000000000000004\n",
            "1- 0.30000000000000004\n",
            "error =  0.7\n",
            "W1(new) = 0.1+0.1*(1-0.30000000000000004)*(1)\n",
            "Weight 1 is: 0.16999999999999998\n",
            "W2(new) = 0.1+0.1*(1-0.30000000000000004)*(1)\n",
            "Weight 2 is:0.16999999999999998\n",
            "b(new) = 0.1+0.1*(1-0.30000000000000004)\n",
            "Bias is:0.16999999999999998\n",
            "Computed error is :0.48999999999999994\n",
            "\n",
            "case:2\n",
            "---------\n",
            "Yn= 0.16999999999999998+(0.16999999999999998*1)+(0.16999999999999998*-1)\n",
            "=0.16999999999999998\n",
            "1- 0.16999999999999998\n",
            "error =  0.8300000000000001\n",
            "W1(new) = 0.16999999999999998+0.1*(1-0.16999999999999998)*(1)\n",
            "Weight 1 is: 0.253\n",
            "W2(new) = 0.16999999999999998+0.1*(1-0.16999999999999998)*(-1)\n",
            "Weight 2 is:0.08699999999999997\n",
            "b(new) = 0.16999999999999998+0.1*(1-0.16999999999999998)\n",
            "Bias is:0.253\n",
            "Computed error is :0.6889000000000001\n",
            "\n",
            "case:3\n",
            "---------\n",
            "Yn= 0.253+(0.253*-1)+(0.08699999999999997*1)\n",
            "=0.08699999999999997\n",
            "1- 0.08699999999999997\n",
            "error =  0.913\n",
            "W1(new) = 0.253+0.1*(1-0.08699999999999997)*(-1)\n",
            "Weight 1 is: 0.1617\n",
            "W2(new) = 0.08699999999999997+0.1*(1-0.08699999999999997)*(1)\n",
            "Weight 2 is:0.17829999999999996\n",
            "b(new) = 0.253+0.1*(1-0.08699999999999997)\n",
            "Bias is:0.3443\n",
            "Computed error is :0.8335690000000001\n",
            "\n",
            "case:4\n",
            "---------\n",
            "Yn= 0.3443+(0.1617*-1)+(0.17829999999999996*-1)\n",
            "=0.004300000000000026\n",
            "-1- 0.004300000000000026\n",
            "error =  -1.0043\n",
            "W1(new) = 0.1617+0.1*(1-0.004300000000000026)*(-1)\n",
            "Weight 1 is: 0.26213000000000003\n",
            "W2(new) = 0.17829999999999996+0.1*(1-0.004300000000000026)*(-1)\n",
            "Weight 2 is:0.27873\n",
            "b(new) = 0.3443+0.1*(1-0.004300000000000026)\n",
            "Bias is:0.24386999999999998\n",
            "Computed error is :1.00861849\n",
            "sum of squared error =  0.7552718725 \n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "epoch : 2\n",
            "--------\n",
            "\n",
            "case:1\n",
            "---------\n",
            "Yn= 0.24386999999999998+(0.26213000000000003*1)+(0.27873*1)\n",
            "=0.7847299999999999\n",
            "1- 0.7847299999999999\n",
            "error =  0.21527000000000007\n",
            "W1(new) = 0.26213000000000003+0.1*(1-0.7847299999999999)*(1)\n",
            "Weight 1 is: 0.28365700000000005\n",
            "W2(new) = 0.27873+0.1*(1-0.7847299999999999)*(1)\n",
            "Weight 2 is:0.300257\n",
            "b(new) = 0.24386999999999998+0.1*(1-0.7847299999999999)\n",
            "Bias is:0.265397\n",
            "Computed error is :0.04634117290000003\n",
            "\n",
            "case:2\n",
            "---------\n",
            "Yn= 0.265397+(0.28365700000000005*1)+(0.300257*-1)\n",
            "=0.24879700000000005\n",
            "1- 0.24879700000000005\n",
            "error =  0.751203\n",
            "W1(new) = 0.28365700000000005+0.1*(1-0.24879700000000005)*(1)\n",
            "Weight 1 is: 0.3587773000000001\n",
            "W2(new) = 0.300257+0.1*(1-0.24879700000000005)*(-1)\n",
            "Weight 2 is:0.2251367\n",
            "b(new) = 0.265397+0.1*(1-0.24879700000000005)\n",
            "Bias is:0.3405173\n",
            "Computed error is :0.564305947209\n",
            "\n",
            "case:3\n",
            "---------\n",
            "Yn= 0.3405173+(0.3587773000000001*-1)+(0.2251367*1)\n",
            "=0.20687669999999994\n",
            "1- 0.20687669999999994\n",
            "error =  0.7931233000000001\n",
            "W1(new) = 0.3587773000000001+0.1*(1-0.20687669999999994)*(-1)\n",
            "Weight 1 is: 0.27946497000000003\n",
            "W2(new) = 0.2251367+0.1*(1-0.20687669999999994)*(1)\n",
            "Weight 2 is:0.30444903\n",
            "b(new) = 0.3405173+0.1*(1-0.20687669999999994)\n",
            "Bias is:0.41982963000000006\n",
            "Computed error is :0.6290445690028902\n",
            "\n",
            "case:4\n",
            "---------\n",
            "Yn= 0.41982963000000006+(0.27946497000000003*-1)+(0.30444903*-1)\n",
            "=-0.16408436999999998\n",
            "-1- -0.16408436999999998\n",
            "error =  -0.83591563\n",
            "W1(new) = 0.27946497000000003+0.1*(1--0.16408436999999998)*(-1)\n",
            "Weight 1 is: 0.36305653300000007\n",
            "W2(new) = 0.30444903+0.1*(1--0.16408436999999998)*(-1)\n",
            "Weight 2 is:0.38804059300000004\n",
            "b(new) = 0.41982963000000006+0.1*(1--0.16408436999999998)\n",
            "Bias is:0.33623806700000003\n",
            "Computed error is :0.6987549404782969\n",
            "sum of squared error =  0.4846116573975468 \n",
            "\n",
            "\n",
            "---------------------------------------------\n",
            "epoch : 3\n",
            "--------\n",
            "\n",
            "case:1\n",
            "---------\n",
            "Yn= 0.33623806700000003+(0.36305653300000007*1)+(0.38804059300000004*1)\n",
            "=1.0873351930000001\n",
            "1- 1.0873351930000001\n",
            "error =  -0.08733519300000014\n",
            "W1(new) = 0.36305653300000007+0.1*(1-1.0873351930000001)*(1)\n",
            "Weight 1 is: 0.3543230137000001\n",
            "W2(new) = 0.38804059300000004+0.1*(1-1.0873351930000001)*(1)\n",
            "Weight 2 is:0.37930707370000005\n",
            "b(new) = 0.33623806700000003+0.1*(1-1.0873351930000001)\n",
            "Bias is:0.32750454770000004\n",
            "Computed error is :0.007627435936347274\n",
            "\n",
            "case:2\n",
            "---------\n",
            "Yn= 0.32750454770000004+(0.3543230137000001*1)+(0.37930707370000005*-1)\n",
            "=0.30252048770000006\n",
            "1- 0.30252048770000006\n",
            "error =  0.6974795122999999\n",
            "W1(new) = 0.3543230137000001+0.1*(1-0.30252048770000006)*(1)\n",
            "Weight 1 is: 0.42407096493000007\n",
            "W2(new) = 0.37930707370000005+0.1*(1-0.30252048770000006)*(-1)\n",
            "Weight 2 is:0.30955912247000006\n",
            "b(new) = 0.32750454770000004+0.1*(1-0.30252048770000006)\n",
            "Bias is:0.39725249893000003\n",
            "Computed error is :0.48647767007824577\n",
            "\n",
            "case:3\n",
            "---------\n",
            "Yn= 0.39725249893000003+(0.42407096493000007*-1)+(0.30955912247000006*1)\n",
            "=0.28274065647\n",
            "1- 0.28274065647\n",
            "error =  0.71725934353\n",
            "W1(new) = 0.42407096493000007+0.1*(1-0.28274065647)*(-1)\n",
            "Weight 1 is: 0.35234503057700006\n",
            "W2(new) = 0.30955912247000006+0.1*(1-0.28274065647)*(1)\n",
            "Weight 2 is:0.38128505682300007\n",
            "b(new) = 0.39725249893000003+0.1*(1-0.28274065647)\n",
            "Bias is:0.46897843328300004\n",
            "Computed error is :0.5144609658810865\n",
            "\n",
            "case:4\n",
            "---------\n",
            "Yn= 0.46897843328300004+(0.35234503057700006*-1)+(0.38128505682300007*-1)\n",
            "=-0.2646516541170001\n",
            "-1- -0.2646516541170001\n",
            "error =  -0.7353483458829999\n",
            "W1(new) = 0.35234503057700006+0.1*(1--0.2646516541170001)*(-1)\n",
            "Weight 1 is: 0.4258798651653001\n",
            "W2(new) = 0.38128505682300007+0.1*(1--0.2646516541170001)*(-1)\n",
            "Weight 2 is:0.4548198914113001\n",
            "b(new) = 0.46897843328300004+0.1*(1--0.2646516541170001)\n",
            "Bias is:0.3954435986947\n",
            "Computed error is :0.5407371897928641\n",
            "sum of squared error =  0.3873258154221359 \n",
            "\n",
            "\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# import the module numpy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# the features for the or model , here we have\n",
        "# taken the possible values for combination of\n",
        "# two inputs\n",
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "\n",
        "# labels for the or model, here the output for\n",
        "# the features is taken as an array\n",
        "labels = np.array([1, 1, 1, -1])\n",
        "\n",
        "# to print the features and the labels for\n",
        "# which the model has to be trained\n",
        "print(features, labels)\n",
        "\n",
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.1, 0.1]\n",
        "bias = 0.1\n",
        "learning_rate = 0.1\n",
        "epoch = 3\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "\t# epoch is the number of the model is trained\n",
        "\t# with the same data\n",
        "\tprint(\"epoch :\", i+1)\n",
        "\tprint(\"--------\")\n",
        "\n",
        "\t# variable to check if there is no change in previous\n",
        "\t# weight and present calculated weight\n",
        "\t# initial error is kept as 0\n",
        "\tsum_squared_error = 0.0\n",
        "\n",
        "\t# for each of the possible input given in the features\n",
        "\tfor j in range(features.shape[0]):\n",
        "\t\tprint(\"\")\n",
        "\t\tprint(f\"case:{j+1}\")\n",
        "\t\tprint(\"---------\")\n",
        "\n",
        "\t\t# actual output to be obtained\n",
        "\t\tactual = labels[j]\n",
        "\n",
        "\t\t# the value of two features as given in the features\n",
        "\t\t# array\n",
        "\t\tx1 = features[j][0]\n",
        "\t\tx2 = features[j][1]\n",
        "\n",
        "\t\t# net unit value computation performed to obtain the\n",
        "\t\t# sum of features multiplied with their weights\n",
        "\t\tprint(f\"Yn= {bias}+({weight[0]}*{x1})+({weight[1]}*{x2})\")\n",
        "\t\tunit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n",
        "\t\tprint(f\"={unit}\")\n",
        "\n",
        "\t\t# error is computed so as to update the weights\n",
        "\t\tprint(f\"{actual}- {unit}\")\n",
        "\t\terror = actual - unit\n",
        "\n",
        "\t\t# print statement to print the actual value , predicted\n",
        "\t\t# value and the error\n",
        "\t\tprint(\"error = \", error)\n",
        "\n",
        "\t\t# summation of squared error is calculated\n",
        "\t\tsum_squared_error += error * error\n",
        "\n",
        "\t\t# updation of weights, summing up of product of learning rate ,\n",
        "\t\t# sum of squared error and feature value\n",
        "\t\tprint(f\"W1(new) = {weight[0]}+{learning_rate}*({labels[i]}-{unit})*({x1})\")\n",
        "\t\tweight[0] += learning_rate * error * x1\n",
        "\t\tprint(f\"Weight 1 is: {weight[0]}\")\n",
        "\n",
        "\t\tprint(f\"W2(new) = {weight[1]}+{learning_rate}*({labels[i]}-{unit})*({x2})\")\n",
        "\t\tweight[1] += learning_rate * error * x2\n",
        "\t\tprint(f\"Weight 2 is:{weight[1]}\")\n",
        "\n",
        "\t\t# updation of bias, summing up of product of learning rate and\n",
        "\t\t# sum of squared error\n",
        "\t\tprint(f\"b(new) = {bias}+{learning_rate}*({labels[i]}-{unit})\")\n",
        "\t\tbias += learning_rate * error\n",
        "\t\tprint(f\"Bias is:{bias}\")\n",
        "\t\tprint(f\"Computed error is :{error**2}\")\n",
        "\n",
        "\tprint(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")\n",
        "\tprint(\"---------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Madalin for AND"
      ],
      "metadata": {
        "id": "IcF5fgc09jEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Python Libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Sigmoid Function\n",
        "def sigmoid(z):\n",
        "\treturn 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Initialization of the neural network parameters\n",
        "# Initialized all the weights in the range of between 0 and 1\n",
        "# Bias values are initialized to 0\n",
        "\n",
        "def initializeParameters(inputFeatures, neuronsInHiddenLayers, outputFeatures):\n",
        "\t# W1 = np.random.randn(neuronsInHiddenLayers, inputFeatures)\n",
        "\t# W2 = np.random.randn(outputFeatures, neuronsInHiddenLayers)\n",
        "\t# b1 = np.zeros((neuronsInHiddenLayers, 1))\n",
        "\t# b2 = np.zeros((outputFeatures, 1))\n",
        "\tW1 =0\n",
        "\tW2 =0\n",
        "\tb1 =0\n",
        "\tb2 =0\n",
        "\n",
        "\t\n",
        "\tparameters = {\"W1\" : W1, \"b1\": b1,\n",
        "\t\t\t\t\"W2\" : W2, \"b2\": b2}\n",
        "\treturn parameters\n",
        "\n",
        "# Forward Propagation\n",
        "def forwardPropagation(X, Y, parameters):\n",
        "\tm = X.shape[1]\n",
        "\tW1 = parameters[\"W1\"]\n",
        "\tW2 = parameters[\"W2\"]\n",
        "\tb1 = parameters[\"b1\"]\n",
        "\tb2 = parameters[\"b2\"]\n",
        "\n",
        "\tZ1 = np.dot(W1, X) + b1\n",
        "\tA1 = sigmoid(Z1)\n",
        "\tZ2 = np.dot(W2, A1) + b2\n",
        "\tA2 = sigmoid(Z2)\n",
        "\n",
        "\tcache = (Z1, A1, W1, b1, Z2, A2, W2, b2)\n",
        "\tlogprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n",
        "\tcost = -np.sum(logprobs) / m\n",
        "\treturn cost, cache, A2\n",
        "\n",
        "# Backward Propagation\n",
        "def backwardPropagation(X, Y, cache):\n",
        "\tm = X.shape[1]\n",
        "\t(Z1, A1, W1, b1, Z2, A2, W2, b2) = cache\n",
        "\t\n",
        "\tdZ2 = A2 - Y\n",
        "\tdW2 = np.dot(dZ2, A1.T) / m\n",
        "\tdb2 = np.sum(dZ2, axis = 1, keepdims = True)\n",
        "\t\n",
        "\tdA1 = np.dot(W2.T, dZ2)\n",
        "\tdZ1 = np.multiply(dA1, A1 * (1- A1))\n",
        "\tdW1 = np.dot(dZ1, X.T) / m\n",
        "\tdb1 = np.sum(dZ1, axis = 1, keepdims = True) / m\n",
        "\t\n",
        "\tgradients = {\"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2,\n",
        "\t\t\t\t\"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n",
        "\treturn gradients\n",
        "\n",
        "# Updating the weights based on the negative gradients\n",
        "def updateParameters(parameters, gradients, learningRate):\n",
        "\tparameters[\"W1\"] = parameters[\"W1\"] - learningRate * gradients[\"dW1\"]\n",
        "\tparameters[\"W2\"] = parameters[\"W2\"] - learningRate * gradients[\"dW2\"]\n",
        "\tparameters[\"b1\"] = parameters[\"b1\"] - learningRate * gradients[\"db1\"]\n",
        "\tparameters[\"b2\"] = parameters[\"b2\"] - learningRate * gradients[\"db2\"]\n",
        "\treturn parameters\n",
        "\n",
        "\n",
        "\n",
        "#program wxwcution starts here\n",
        "# Model to learn the AND truth table\n",
        "X = np.array([[1, 1, -1, -1], [0, 1, 0, 1]]) # XOR input\n",
        "Y = np.array([[1, -1, 1, -1]]) # AND function\n",
        "\n",
        "# Define model parameters\n",
        "neuronsInHiddenLayers = 1 # number of hidden layer neurons (2)\n",
        "inputFeatures = X.shape[0] # number of input features (2)\n",
        "outputFeatures = Y.shape[0] # number of output features (1)\n",
        "parameters = initializeParameters(inputFeatures, neuronsInHiddenLayers, outputFeatures)\n",
        "epoch = 3\n",
        "learningRate = 1\n",
        "losses = np.zeros((epoch, 1))\n",
        "\n",
        "for i in range(epoch):\n",
        "\tlosses[i, 0], cache, A2 = forwardPropagation(X, Y, parameters)\n",
        "\tgradients = backwardPropagation(X, Y, cache)\n",
        "\tparameters = updateParameters(parameters, gradients, learningRate)\n",
        "\n",
        "# Evaluating the performance\n",
        "plt.figure()\n",
        "plt.plot(losses)\n",
        "plt.xlabel(\"EPOCHS\")\n",
        "plt.ylabel(\"Loss value\")\n",
        "plt.show()\n",
        "\n",
        "# Testing\n",
        "X = np.array([[1, 1, 0, 0], [0, 1, 0, 1]]) # XOR input\n",
        "cost, _, A2 = forwardPropagation(X, Y, parameters)\n",
        "prediction = (A2 > 0.5) * 1.0\n",
        "# print(A2)\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "id": "5yLM9aKS9mGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Madaline for AND function"
      ],
      "metadata": {
        "id": "bxpA4gEK6mM-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YWDDgwcb6tkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}