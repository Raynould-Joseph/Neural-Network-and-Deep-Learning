{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJnfJOVW6h0MkEB9fE6Lld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raynould-Joseph/Neural-Network-and-Deep-Learning/blob/main/MLP_classifier_Lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explore MLP classifier\n",
        "# 2. Give a summary of all the parameters used in MLP classifier.\n",
        "# 3. Classify an XOR problem using the multilayer perceptron Network\n",
        "# 4. Use atleast 3 different activation functions and give your inference.\n",
        "# 5. Print the final weight values"
      ],
      "metadata": {
        "id": "YjXuhjeT6OSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explore MLP classifier\n"
      ],
      "metadata": {
        "id": "KDB1WqzS6a8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fully connected multi-layer neural network is called a Multilayer Perceptron (MLP)."
      ],
      "metadata": {
        "id": "IZdNTl0woVn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It has 3 layers including one hidden layer. If it has more than 1 hidden layer, it is called a deep ANN. An MLP is a typical example of a feedforward artificial neural network. In this figure, the ith activation unit in the lth layer is denoted as ai(l).\n",
        "\n",
        "The number of layers and the number of neurons are referred to as hyperparameters of a neural network, and these need tuning. Cross-validation techniques must be used to find ideal values for these.\n",
        "\n",
        "The weight adjustment training is done via backpropagation. Deeper neural networks are better at processing data. However, deeper layers can lead to vanishing gradient problems. Special algorithms are required to solve this issue."
      ],
      "metadata": {
        "id": "eihc7aeNocVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.simplilearn.com/ice9/free_resources_article_thumb/MultilayerANN_3.jpg"
      ],
      "metadata": {
        "id": "hQq3FPmDqPGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ai(in) refers to the ith value in the input layer\n",
        "\n",
        "ai(h) refers to the ith unit in the hidden layer\n",
        "\n",
        "ai(out) refers to the ith unit in the output layer\n",
        "\n",
        "ao(in) is simply the bias unit and is equal to 1; it will have the corresponding weight w0\n",
        "\n",
        "The weight coefficient from layer l to layer l+1 is represented by wk,j(l)"
      ],
      "metadata": {
        "id": "uLAIde1lqSp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slXakOBx5Yvq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Give a summary of all the parameters used in MLP classifier"
      ],
      "metadata": {
        "id": "NL0A9e4-6hRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "train_data = np.array(\n",
        "    [\n",
        "        [0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]])\n",
        "\n",
        "target_xor = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [1],\n",
        "        [1],\n",
        "        [0]])\n",
        "\n",
        "target_nand = np.array(\n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1],\n",
        "        [0]])\n",
        "\n",
        "target_or = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]])\n",
        "\n",
        "target_and = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [0],\n",
        "        [0],\n",
        "        [1]])\n",
        "def train(self):\n",
        "    \"\"\"\n",
        "    Train a single layer perceptron.\n",
        "    \"\"\"\n",
        "    # the number of consecutive correct classifications\n",
        "    correct_counter = 0\n",
        "\n",
        "    for train, target in cycle(zip(self.train_data, self.target)):\n",
        "        # end if all points are correctly classified\n",
        "        if correct_counter == len(self.train_data):\n",
        "            break\n",
        "\n",
        "        output = self.classify(train)\n",
        "        self.node_val = train\n",
        "\n",
        "        if output == target:\n",
        "            correct_counter += 1\n",
        "        else:\n",
        "            # if incorrectly classified, update weights and reset correct_counter\n",
        "            self.update_weights(target, output)\n",
        "            correct_counter = 0\n",
        "def _gradient(self, node, exp, output):\n",
        "    \"\"\"\n",
        "    Return the gradient for a weight.\n",
        "    This is the value of delta-w.\n",
        "    \"\"\"\n",
        "    return node * (exp - output)\n",
        "\n",
        "def update_weights(self, exp, output):\n",
        "    \"\"\"\n",
        "    Update weights and bias based on their respective gradients\n",
        "    \"\"\"\n",
        "    for i in range(self.input_nodes):\n",
        "        self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
        "\n",
        "    # the value of the bias node can be considered as being 1 and the weight between this node\n",
        "    # and the output node being self.b\n",
        "    self.b += self.lr * self._gradient(1, exp, output)\n",
        "\n",
        "def forward(self, datapoint):\n",
        "    \"\"\"\n",
        "    One forward pass through the perceptron.\n",
        "    Implementation of \"wX + b\".\n",
        "    \"\"\"\n",
        "    return self.b + np.dot(self.w, datapoint)\n",
        "\n",
        "def classify(self, datapoint):\n",
        "    \"\"\"\n",
        "    Return the class to which a datapoint belongs based on\n",
        "    the perceptron's output for that point.\n",
        "    \"\"\"\n",
        "    if self.forward(datapoint) >= 0:\n",
        "        return 1\n",
        "def plot(self, h=0.01):\n",
        "    \"\"\"\n",
        "    Generate plot of input data and decision boundary.\n",
        "    \"\"\"\n",
        "    # setting plot properties like size, theme and axis limits\n",
        "    sns.set_style('darkgrid')\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.xlim(-0.1, 1.1)\n",
        "    plt.ylim(-0.1, 1.1)\n",
        "\n",
        "    colors = {\n",
        "        0: \"ro\",\n",
        "        1: \"go\"\n",
        "    }\n",
        "\n",
        "    # plotting the four datapoints\n",
        "    for i in range(len(self.train_data)):\n",
        "        plt.plot([self.train_data[i][0]],\n",
        "                 [self.train_data[i][1]],\n",
        "                 colors[self.target[i][0]],\n",
        "                 markersize=20)\n",
        "\n",
        "    x_range = np.arange(-0.1, 1.1, h)\n",
        "    y_range = np.arange(-0.1, 1.1, h)\n",
        "\n",
        "    # creating a mesh to plot decision boundary\n",
        "    xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
        "    Z = np.array([[self.classify([x, y]) for x in x_range] for y in y_range])\n",
        "\n",
        "    # using the contourf function to create the plot\n",
        "    plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'blue'], alpha=0.4)        \n"
      ],
      "metadata": {
        "id": "MQvT1LFp6kbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Classify an XOR problem using the multilayer perceptron Network"
      ],
      "metadata": {
        "id": "Mny1vbET6M6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import cycle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "o7muQRH26tB4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.array(\n",
        "    [\n",
        "        [0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]])\n",
        "\n",
        "target_xor = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [1],\n",
        "        [1],\n",
        "        [0]])\n",
        "\n",
        "target_nand = np.array(\n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1],\n",
        "        [0]])\n",
        "\n",
        "target_or = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]])\n",
        "\n",
        "target_and = np.array(\n",
        "    [\n",
        "        [0],\n",
        "        [0],\n",
        "        [0],\n",
        "        [1]])"
      ],
      "metadata": {
        "id": "fFxFyfIyvK2K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self):\n",
        "    \"\"\"\n",
        "    Train a single layer perceptron.\n",
        "    \"\"\"\n",
        "    # the number of consecutive correct classifications\n",
        "    correct_counter = 0\n",
        "\n",
        "    for train, target in cycle(zip(self.train_data, self.target)):\n",
        "        # end if all points are correctly classified\n",
        "        if correct_counter == len(self.train_data):\n",
        "            break\n",
        "\n",
        "        output = self.classify(train)\n",
        "        self.node_val = train\n",
        "\n",
        "        if output == target:\n",
        "            correct_counter += 1\n",
        "        else:\n",
        "            # if incorrectly classified, update weights and reset correct_counter\n",
        "            self.update_weights(target, output)\n",
        "            correct_counter = 0"
      ],
      "metadata": {
        "id": "hBYO6iJlvXNc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _gradient(self, node, exp, output):\n",
        "    \"\"\"\n",
        "    Return the gradient for a weight.\n",
        "    This is the value of delta-w.\n",
        "    \"\"\"\n",
        "    return node * (exp - output)\n",
        "\n",
        "def update_weights(self, exp, output):\n",
        "    \"\"\"\n",
        "    Update weights and bias based on their respective gradients\n",
        "    \"\"\"\n",
        "    for i in range(self.input_nodes):\n",
        "        self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
        "\n",
        "    # the value of the bias node can be considered as being 1 and the weight between this node\n",
        "    # and the output node being self.b\n",
        "    self.b += self.lr * self._gradient(1, exp, output)\n",
        "\n",
        "def forward(self, datapoint):\n",
        "    \"\"\"\n",
        "    One forward pass through the perceptron.\n",
        "    Implementation of \"wX + b\".\n",
        "    \"\"\"\n",
        "    return self.b + np.dot(self.w, datapoint)\n",
        "\n",
        "def classify(self, datapoint):\n",
        "    \"\"\"\n",
        "    Return the class to which a datapoint belongs based on\n",
        "    the perceptron's output for that point.\n",
        "    \"\"\"\n",
        "    if self.forward(datapoint) >= 0:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "odSoqFKNveA4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(self, h=0.01):\n",
        "    \"\"\"\n",
        "    Generate plot of input data and decision boundary.\n",
        "    \"\"\"\n",
        "    # setting plot properties like size, theme and axis limits\n",
        "    sns.set_style('darkgrid')\n",
        "    plt.figure(figsize=(20, 20))\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.xlim(-0.1, 1.1)\n",
        "    plt.ylim(-0.1, 1.1)\n",
        "\n",
        "    colors = {\n",
        "        0: \"ro\",\n",
        "        1: \"go\"\n",
        "    }\n",
        "\n",
        "    # plotting the four datapoints\n",
        "    for i in range(len(self.train_data)):\n",
        "        plt.plot([self.train_data[i][0]],\n",
        "                 [self.train_data[i][1]],\n",
        "                 colors[self.target[i][0]],\n",
        "                 markersize=20)\n",
        "\n",
        "    x_range = np.arange(-0.1, 1.1, h)\n",
        "    y_range = np.arange(-0.1, 1.1, h)\n",
        "\n",
        "    # creating a mesh to plot decision boundary\n",
        "    xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
        "    Z = np.array([[self.classify([x, y]) for x in x_range] for y in y_range])\n",
        "\n",
        "    # using the contourf function to create the plot\n",
        "    plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'blue'], alpha=0.4)"
      ],
      "metadata": {
        "id": "TPNQgI-_vjAw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    \"\"\"\n",
        "    Create a perceptron.\n",
        "    train_data: A 4x2 matrix with the input data.\n",
        "    target: A 4x1 matrix with the perceptron's expected outputs\n",
        "    lr: the learning rate. Defaults to 0.01\n",
        "    input_nodes: the number of nodes in the input layer of the perceptron.\n",
        "        Should be equal to the second dimension of train_data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_data, target, lr=0.01, input_nodes=2):\n",
        "        self.train_data = train_data\n",
        "        self.target = target\n",
        "        self.lr = lr\n",
        "        self.input_nodes = input_nodes\n",
        "\n",
        "        # randomly initialize the weights and set the bias to -1.\n",
        "        self.w = np.random.uniform(size=self.input_nodes)\n",
        "        self.b = -1\n",
        "\n",
        "        # node_val hold the values of each node at a given point of time.\n",
        "        self.node_val = np.zeros(self.input_nodes)\n",
        "\n",
        "    def _gradient(self, node, exp, output):\n",
        "        \"\"\"\n",
        "        Return the gradient for a weight.\n",
        "        This is the value of delta-w.\n",
        "        \"\"\"\n",
        "        return node * (exp - output)\n",
        "\n",
        "    def update_weights(self, exp, output):\n",
        "        \"\"\"\n",
        "        Update weights and bias based on their respective gradients\n",
        "        \"\"\"\n",
        "        for i in range(self.input_nodes):\n",
        "            self.w[i] += self.lr * self._gradient(self.node_val[i], exp, output)\n",
        "\n",
        "        # the value of the bias node can be considered as being 1 and the weight between this node\n",
        "        # and the output node being self.b\n",
        "        self.b += self.lr * self._gradient(1, exp, output)\n",
        "\n",
        "    def forward(self, datapoint):\n",
        "        \"\"\"\n",
        "        One forward pass through the perceptron.\n",
        "        Implementation of \"wX + b\".\n",
        "        \"\"\"\n",
        "        return self.b + np.dot(self.w, datapoint)\n",
        "\n",
        "    def classify(self, datapoint):\n",
        "        \"\"\"\n",
        "        Return the class to which a datapoint belongs based on\n",
        "        the perceptron's output for that point.\n",
        "        \"\"\"\n",
        "        if self.forward(datapoint) >= 0:\n",
        "            return 1\n",
        "\n",
        "        return 0\n",
        "    def plot(self, h=0.01):\n",
        "        \"\"\"\n",
        "        Generate plot of input data and decision boundary.\n",
        "        \"\"\"\n",
        "        # setting plot properties like size, theme and axis limits\n",
        "        sns.set_style('darkgrid')\n",
        "        plt.figure(figsize=(20, 20))\n",
        "\n",
        "        plt.axis('scaled')\n",
        "        plt.xlim(-0.1, 1.1)\n",
        "        plt.ylim(-0.1, 1.1)\n",
        "\n",
        "        colors = {\n",
        "            0: \"ro\",\n",
        "            1: \"go\"\n",
        "        }\n",
        "\n",
        "        # plotting the four datapoints\n",
        "        for i in range(len(self.train_data)):\n",
        "            plt.plot([self.train_data[i][0]],\n",
        "                     [self.train_data[i][1]],\n",
        "                     colors[self.target[i][0]],\n",
        "                     markersize=20)\n",
        "\n",
        "        x_range = np.arange(-0.1, 1.1, h)\n",
        "        y_range = np.arange(-0.1, 1.1, h)\n",
        "\n",
        "        # creating a mesh to plot decision boundary\n",
        "        xx, yy = np.meshgrid(x_range, y_range, indexing='ij')\n",
        "        Z = np.array([[self.classify([x, y]) for x in x_range] for y in y_range])\n",
        "\n",
        "        # using the contourf function to create the plot\n",
        "        plt.contourf(xx, yy, Z, colors=['red', 'green', 'green', 'blue'], alpha=0.4)\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train a single layer perceptron.\n",
        "        \"\"\"\n",
        "        # the number of consecutive correct classifications\n",
        "        correct_counter = 0\n",
        "\n",
        "        for train, target in cycle(zip(self.train_data, self.target)):\n",
        "            # end if all points are correctly classified\n",
        "            if correct_counter == len(self.train_data):\n",
        "                break\n",
        "\n",
        "            output = self.classify(train)\n",
        "            self.node_val = train\n",
        "\n",
        "            if output == target:\n",
        "                correct_counter += 1\n",
        "            else:\n",
        "                # if incorrectly classified, update weights and reset correct_counter\n",
        "                self.update_weights(target, output)\n",
        "                correct_counter = 0\n",
        "        "
      ],
      "metadata": {
        "id": "jy-U4SAIvsF7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_or = Perceptron(train_data, target_or)\n",
        "p_or.train()"
      ],
      "metadata": {
        "id": "TIjykzKvwADS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Use atleast 3 different activation functions and give your inference."
      ],
      "metadata": {
        "id": "gMHBufaP6L_9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwalckOb6yPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Print the final weight values"
      ],
      "metadata": {
        "id": "VkAwPzYJ6LPb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CINHoICw628U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}